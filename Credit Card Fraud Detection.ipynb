{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e8fc58-f9e4-47c5-83e1-4f9dbb1eb34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest …\n",
      "\n",
      "=======================================================\n",
      "  CREDIT CARD FRAUD DETECTION — MODEL EVALUATION\n",
      "=======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      1.00      1.00      9800\n",
      "       Fraud       1.00      1.00      1.00       200\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "ROC-AUC Score      : 1.0000\n",
      "Avg Precision Score: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "  TN= 9800  FP=    0\n",
      "  FN=    0  TP=  200\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "risk_composite           0.334765\n",
      "geo_risk_score           0.195998\n",
      "velocity_score           0.150449\n",
      "credit_limit_used_pct    0.126226\n",
      "num_transactions_24h     0.070589\n",
      "hour_of_day              0.050006\n",
      "distance_from_home       0.039808\n",
      "num_transactions_1h      0.017288\n",
      "is_international         0.006605\n",
      "days_since_last_txn      0.005022\n",
      "\n",
      "✅  Saved: fraud_model.joblib | scaler.joblib | feature_names.joblib\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Credit Card Fraud Detection - Model Training Script\n",
    "Run this file first to generate: fraud_model.joblib, scaler.joblib, feature_names.joblib\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             roc_auc_score, average_precision_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 1. GENERATE SYNTHETIC CREDIT CARD DATA\n",
    "# ─────────────────────────────────────────────\n",
    "np.random.seed(42)\n",
    "N = 50_000\n",
    "FRAUD_RATE = 0.02  # 2% fraud\n",
    "\n",
    "n_fraud = int(N * FRAUD_RATE)\n",
    "n_legit = N - n_fraud\n",
    "\n",
    "def make_legit(n):\n",
    "    return pd.DataFrame({\n",
    "        'amount':            np.random.lognormal(4.0, 1.2, n),\n",
    "        'hour_of_day':       np.random.choice(range(6, 23), n),\n",
    "        'day_of_week':       np.random.choice(range(7), n),\n",
    "        'merchant_category': np.random.choice(range(10), n),\n",
    "        'num_transactions_1h':  np.random.poisson(1.5, n),\n",
    "        'num_transactions_24h': np.random.poisson(5, n),\n",
    "        'avg_amount_30d':    np.random.lognormal(3.8, 0.9, n),\n",
    "        'distance_from_home': np.random.exponential(20, n),\n",
    "        'is_online':         np.random.choice([0, 1], n, p=[0.6, 0.4]),\n",
    "        'is_international':  np.random.choice([0, 1], n, p=[0.95, 0.05]),\n",
    "        'card_present':      np.random.choice([0, 1], n, p=[0.3, 0.7]),\n",
    "        'days_since_last_txn': np.random.exponential(2, n),\n",
    "        'credit_limit_used_pct': np.random.beta(2, 8, n),\n",
    "        'velocity_score':    np.random.beta(2, 10, n),\n",
    "        'geo_risk_score':    np.random.beta(1, 15, n),\n",
    "    })\n",
    "\n",
    "def make_fraud(n):\n",
    "    return pd.DataFrame({\n",
    "        'amount':            np.random.lognormal(5.5, 1.5, n),   # higher amounts\n",
    "        'hour_of_day':       np.random.choice(list(range(0, 6)) + list(range(22, 24)), n),  # odd hours\n",
    "        'day_of_week':       np.random.choice(range(7), n),\n",
    "        'merchant_category': np.random.choice(range(10), n),\n",
    "        'num_transactions_1h':  np.random.poisson(4.5, n),       # many transactions\n",
    "        'num_transactions_24h': np.random.poisson(12, n),\n",
    "        'avg_amount_30d':    np.random.lognormal(3.2, 0.8, n),   # amount deviation\n",
    "        'distance_from_home': np.random.exponential(200, n),     # far from home\n",
    "        'is_online':         np.random.choice([0, 1], n, p=[0.3, 0.7]),\n",
    "        'is_international':  np.random.choice([0, 1], n, p=[0.5, 0.5]),  # often international\n",
    "        'card_present':      np.random.choice([0, 1], n, p=[0.7, 0.3]),\n",
    "        'days_since_last_txn': np.random.exponential(0.5, n),    # very recent\n",
    "        'credit_limit_used_pct': np.random.beta(8, 2, n),        # near limit\n",
    "        'velocity_score':    np.random.beta(8, 2, n),\n",
    "        'geo_risk_score':    np.random.beta(8, 2, n),\n",
    "    })\n",
    "\n",
    "df_legit = make_legit(n_legit)\n",
    "df_legit['is_fraud'] = 0\n",
    "df_fraud = make_fraud(n_fraud)\n",
    "df_fraud['is_fraud'] = 1\n",
    "\n",
    "df = pd.concat([df_legit, df_fraud]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Add derived features\n",
    "df['amount_to_avg_ratio'] = df['amount'] / (df['avg_amount_30d'] + 1)\n",
    "df['txn_burst']           = df['num_transactions_1h'] / (df['num_transactions_24h'] + 1)\n",
    "df['risk_composite']      = (df['velocity_score'] + df['geo_risk_score']) / 2\n",
    "\n",
    "FEATURES = [\n",
    "    'amount', 'hour_of_day', 'day_of_week', 'merchant_category',\n",
    "    'num_transactions_1h', 'num_transactions_24h', 'avg_amount_30d',\n",
    "    'distance_from_home', 'is_online', 'is_international', 'card_present',\n",
    "    'days_since_last_txn', 'credit_limit_used_pct', 'velocity_score',\n",
    "    'geo_risk_score', 'amount_to_avg_ratio', 'txn_burst', 'risk_composite'\n",
    "]\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df['is_fraud']\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 2. TRAIN / TEST SPLIT\n",
    "# ─────────────────────────────────────────────\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 3. SCALE FEATURES\n",
    "# ─────────────────────────────────────────────\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc  = scaler.transform(X_test)\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 4. TRAIN RANDOM FOREST (main model)\n",
    "# ─────────────────────────────────────────────\n",
    "print(\"Training Random Forest …\")\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 5. EVALUATE\n",
    "# ─────────────────────────────────────────────\n",
    "y_pred  = model.predict(X_test_sc)\n",
    "y_proba = model.predict_proba(X_test_sc)[:, 1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(\"  CREDIT CARD FRAUD DETECTION — MODEL EVALUATION\")\n",
    "print(\"=\"*55)\n",
    "print(classification_report(y_test, y_pred, target_names=['Legitimate', 'Fraud']))\n",
    "print(f\"ROC-AUC Score      : {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "print(f\"Avg Precision Score: {average_precision_score(y_test, y_proba):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"  TN={cm[0,0]:5d}  FP={cm[0,1]:5d}\")\n",
    "print(f\"  FN={cm[1,0]:5d}  TP={cm[1,1]:5d}\")\n",
    "\n",
    "# Feature importances\n",
    "fi = pd.Series(model.feature_importances_, index=FEATURES).sort_values(ascending=False)\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "print(fi.head(10).to_string())\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 6. SAVE ARTIFACTS\n",
    "# ─────────────────────────────────────────────\n",
    "joblib.dump(model,    'fraud_model.joblib')\n",
    "joblib.dump(scaler,   'scaler.joblib')\n",
    "joblib.dump(FEATURES, 'feature_names.joblib')\n",
    "\n",
    "print(\"\\n✅  Saved: fraud_model.joblib | scaler.joblib | feature_names.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4fee4-03bf-4775-adaf-5dbd4c5b5d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b99a4-8c40-4689-bbf8-f4ca6ed10928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
